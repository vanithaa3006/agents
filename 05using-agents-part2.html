<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>LangChain 1.0 Agents – Hands-on Guide (Part 2)</title>
  <style>
    body {
      font-family: system-ui, -apple-system, BlinkMacSystemFont, "Segoe UI", sans-serif;
      line-height: 1.6;
      margin: 0;
      padding: 0;
      background: radial-gradient(circle at top left, #eef2ff 0, #f9fafb 40%, #fdf2ff 100%);
      color: #111827;
    }
    main {
      max-width: 960px;
      margin: 2rem auto 3rem;
      padding: 2.5rem 2rem 3rem;
      background-color: #ffffff;
      border-radius: 16px;
      box-shadow:
        0 18px 45px rgba(15, 23, 42, 0.08),
        0 0 0 1px rgba(148, 163, 184, 0.12);
    }
    h1 {
      font-size: 2.2rem;
      margin: 0 0 1.25rem;
      letter-spacing: -0.03em;
      text-align: center;
      color: #0f172a;
      padding: 1rem 1.5rem;
      border-radius: 999px;
      background: linear-gradient(135deg, #dbeafe, #e0f2fe);
      box-shadow:
        0 10px 25px rgba(15, 23, 42, 0.12),
        0 0 0 1px rgba(148, 163, 184, 0.35);
    }
    h2 {
      font-size: 1.6rem;
      margin-top: 2.25rem;
      margin-bottom: 0.5rem;
      border-bottom: 2px solid rgba(37, 99, 235, 0.18);
      padding-bottom: 0.35rem;
      color: #0f172a;
    }
    h3 {
      font-size: 1.25rem;
      margin-top: 1.75rem;
      color: #0f172a;
    }
    p {
      margin: 0.5rem 0 0.75rem;
    }
    code {
      font-family: "Fira Code", Menlo, Monaco, Consolas, "Courier New", monospace;
      background-color: #f3f4ff;
      padding: 0.12rem 0.3rem;
      border-radius: 4px;
      font-size: 0.95em;
      color: #1d4ed8;
    }
    pre {
      background: linear-gradient(145deg, #020617, #020617 50%, #0b1120);
      color: #e5e7eb;
      padding: 1rem 1.1rem;
      border-radius: 10px;
      overflow-x: auto;
      font-size: 0.9rem;
      margin: 0.75rem 0 1.5rem;
      border: 1px solid rgba(15, 23, 42, 0.6);
    }
    pre code {
      background: none;
      padding: 0;
      color: inherit;
    }
    .note, .exercise {
      padding: 0.9rem 1.1rem;
      margin: 1rem 0 1.5rem;
      border-radius: 10px;
      font-size: 0.95rem;
      border: 1px solid transparent;
    }
    .note {
      border-left: 4px solid #2563eb;
      background: radial-gradient(circle at top left, #eff6ff 0, #e0f2fe 45%, #eef2ff 100%);
      border-color: rgba(37, 99, 235, 0.4);
      box-shadow:
        0 10px 25px rgba(15, 23, 42, 0.08),
        0 0 0 1px rgba(191, 219, 254, 0.9);
    }
    .exercise {
      border-left: 4px solid #16a34a;
      background: linear-gradient(135deg, #ecfdf3, #f0fdf4);
      border-color: rgba(22, 163, 74, 0.4);
    }
    .exercise-title {
      font-weight: 650;
      margin-bottom: 0.25rem;
      text-transform: uppercase;
      letter-spacing: 0.06em;
      font-size: 0.8rem;
      color: #166534;
    }
    ol, ul {
      padding-left: 1.4rem;
    }
    li {
      margin: 0.25rem 0;
    }
    .sample-output-title {
      font-weight: 600;
      margin-top: 0.75rem;
      margin-bottom: 0.25rem;
      color: #0f172a;
    }
  </style>
</head>
<body>
<main>
  <h1>LangChain 1.0 Agents – Hands-on Lab (Part 2)</h1>

  <div class="note">
    <strong>About this part</strong>
    <p>
      This is <strong>Part 2</strong> of the LangChain 1.0 Agents hands-on lab. It continues from Section 6 of Part 1
      and focuses on middleware, dynamic models, error handling, dynamic prompts, and guardrails.
      If you haven’t completed Part 1 yet, start with <code>05using-agents-part1.html</code>.
    </p>
  </div>

  <h2>6. Middleware for Agents</h2>

  <h3>6.1 What Is Middleware?</h3>
  <p>
    <strong>Middleware</strong> is code that runs <em>between</em> different parts of your agent's execution pipeline.
    You can think of it like a filter or interceptor that can:
  </p>
  <ul>
    <li>Modify requests before they reach the model.</li>
    <li>Transform responses after the model processes them.</li>
    <li>Add logging, monitoring, or debugging.</li>
    <li>Implement custom logic for model selection, prompts, or tool handling.</li>
  </ul>
  <p><strong>Why use middleware?</strong></p>
  <ol>
    <li><strong>Separation of concerns</strong>: Keep core logic separate from cross-cutting concerns.</li>
    <li><strong>Reusability</strong>: Reuse middleware across many agents.</li>
    <li><strong>Flexibility</strong>: Change behavior without changing agent business logic.</li>
    <li><strong>Monitoring</strong>: Add logging, metrics, and debugging easily.</li>
  </ol>

  <h3>6.2 Basic Logging Middleware</h3>
  <p>
    Let's start with a simple middleware that logs requests and responses around a model call.
  </p>

  <div class="exercise">
    <div class="exercise-title">Your Task</div>
    <p>
      Create a logging middleware using <code>@wrap_model_call</code> and apply it when creating an agent.
      Copy the code into a new cell and run it.
    </p>
  </div>

  <pre><code># Basic Middleware Example: Request/Response Logger
from langchain.agents.middleware import wrap_model_call
from datetime import datetime

@wrap_model_call
def logging_middleware(request, handler):
    """Simple middleware that logs all model interactions."""
    print(f" [{datetime.now().strftime('%H:%M:%S')}] Model Request:")
    print(f"   Model: {request.model}")
    print(f"   Messages: {len(request.state.get('messages', []))} messages")
    
    # Call the actual model (this is where the magic happens)
    response = handler(request)
    
    print(f"✅ [{datetime.now().strftime('%H:%M:%S')}] Model Response received")
    print(f"   Response type: {type(response)}")
    print("-" * 50)
    
    return response

# Create agent with logging middleware
basic_agent_with_logging = create_agent(
    model=model,
    tools=[calculator, get_time],
    middleware=[logging_middleware],  # Apply our middleware
    system_prompt="You are a helpful assistant with logging capabilities."
)</code></pre>

  <div class="exercise">
    <div class="exercise-title">Your Task</div>
    <p>
      Trigger the logging middleware by invoking the agent. Watch the console to see the logged request and response.
    </p>
  </div>

  <pre><code># Test the logging middleware in action
print("=== Testing Logging Middleware ===")

result = basic_agent_with_logging.invoke({
    "messages": [{"role": "user", "content": "What is 15 + 25? Also, what time is it?"}]
})

print("\nFinal Result:")
print(result["messages"][-1].content)</code></pre>

  <h3>6.3 Key Middleware Concepts</h3>
  <p><strong>Execution Order</strong>: Middleware runs in the order you specify in the list.</p>
  <p><strong>Handler Pattern</strong>:</p>
  <ul>
    <li>Always call <code>handler(request)</code> to continue the chain.</li>
    <li>This is where the actual model call happens.</li>
    <li>If you skip <code>handler</code>, the request stops at your middleware.</li>
  </ul>
  <p><strong>Middleware Types in LangChain</strong>:</p>
  <ul>
    <li><code>@wrap_model_call</code> – intercepts model calls.</li>
    <li><code>@wrap_tool_call</code> – intercepts tool calls.</li>
    <li><code>@dynamic_prompt</code> – dynamically modifies system prompts.</li>
  </ul>
  <p><strong>Best Practices</strong>:</p>
  <ol>
    <li>Keep each middleware focused on a single responsibility.</li>
    <li>Handle exceptions gracefully.</li>
    <li>Order middleware carefully – order matters.</li>
    <li>Use middleware for cross-cutting concerns, not core business logic.</li>
  </ol>

  <h2>7. Static and Dynamic Models</h2>

  <h3>7.1 Static Models</h3>
  <p>
    A <strong>static model</strong> is configured once when creating the agent and stays the same for all requests.
    This is simple and works well when you do not need to switch models based on context.
  </p>

  <div class="exercise">
    <div class="exercise-title">Your Task</div>
    <p>
      Create agents using static models: one with a model identifier string, and another with a configured
      <code>ChatOpenAI</code> instance.
    </p>
  </div>

  <pre><code># Static model example - Model is set once and doesn't change
from langchain.agents import create_agent

# Method 1: Using model identifier string
static_agent_simple = create_agent(
    "openai:gpt-4.1-mini",  # Model identifier string
    tools=[calculator, get_time]
)

# Method 2: Using configured model instance
static_model = ChatOpenAI(
    model="gpt-4.1-mini",
    temperature=0.1,
    max_tokens=1000,
    timeout=30
)

static_agent = create_agent(
    model=static_model,
    tools=[calculator, get_time],
    system_prompt="You are a precise assistant. Always show your calculations step by step."
)

print("Static agents created successfully!")</code></pre>

  <div class="exercise">
    <div class="exercise-title">Your Task</div>
    <p>Invoke the static agent and observe how it explains its calculations step by step.</p>
  </div>

  <pre><code># Test static agent
result = static_agent.invoke({
    "messages": [{"role": "user", "content": "Calculate 25 * 8 - 15 and explain your steps"}]
})

print("Static Agent Response:")
print(result["messages"][-1].content)</code></pre>

  <h3>6.2 Dynamic Models with Middleware</h3>
  <p>
    A <strong>dynamic model</strong> is chosen at runtime, based on the conversation state and context.
    For example, you can use a cheaper model for simple queries and a more powerful model when the task is complex.
  </p>

  <div class="exercise">
    <div class="exercise-title">Your Task</div>
    <p>
      Implement a dynamic model selection middleware that chooses between a basic and an advanced model based on message
      count and keywords in the last user message.
    </p>
  </div>

  <pre><code># Dynamic model example - Now you understand middleware!
from langchain.agents.middleware import wrap_model_call, ModelRequest, ModelResponse

# Set up different models for different scenarios
basic_model = ChatOpenAI(model="gpt-4.1-mini")
advanced_model = ChatOpenAI(model="gpt-4.1")

@wrap_model_call
def dynamic_model_selection(request: ModelRequest, handler) -> ModelResponse:
    """Choose model based on conversation complexity."""
    message_count = len(request.state["messages"])
    
    # Check if the question involves complex calculations or multiple steps
    last_message = request.state["messages"][-1].content if request.state["messages"] else ""
    complex_keywords = ["complex", "multiple", "detailed", "analysis", "explain"]
    
    if message_count &gt; 5 or any(keyword in last_message.lower() for keyword in complex_keywords):
        # Use advanced model for complex scenarios
        print("Using advanced model (GPT-4.1) for complex task")
        request.model = advanced_model
    else:
        # Use basic model for simple tasks
        print("Using basic model (GPT-4.1-mini) for simple task")
        request.model = basic_model
    
    return handler(request)

# Create dynamic agent
dynamic_agent = create_agent(
    model=basic_model,  # Default model
    tools=[calculator, get_time],
    middleware=[dynamic_model_selection],  # This is middleware in action!
    system_prompt="You are an intelligent assistant that adapts to task complexity."
)

print("Dynamic agent created successfully!")</code></pre>

  <div class="exercise">
    <div class="exercise-title">Your Task</div>
    <p>
      Test the dynamic agent with both a simple and a complex query. Watch the console to see which model is selected.
    </p>
  </div>

  <pre><code># Test dynamic agent with simple task
print("Testing with simple task:")
result = dynamic_agent.invoke({
    "messages": [{"role": "user", "content": "What is 5 + 3?"}]
})
print(result["messages"][-1].content)
print("\n" + "="*50 + "\n")

# Test dynamic agent with complex task
print("Testing with complex task:")
result = dynamic_agent.invoke({
    "messages": [{"role": "user", "content": "Please provide a detailed analysis of the calculation 15 * 8 + 22 / 2 - 7"}]
})
print(result["messages"][-1].content)</code></pre>

  <h2>8. Error Handling in Tools</h2>
  <p>
    Tools can fail due to invalid inputs, network issues, or bugs. A robust agent should handle these errors gracefully
    and return <strong>user-friendly messages</strong> instead of crashing.
  </p>

  <div class="exercise">
    <div class="exercise-title">Your Task</div>
    <p>
      Define a division tool that might raise errors (such as division by zero) and then add middleware to catch those
      errors and return clear messages.
    </p>
  </div>

  <pre><code>from langchain.agents.middleware import wrap_tool_call
from langchain_core.messages import ToolMessage

# Create a tool that might fail
@tool
def divide_numbers(dividend: float, divisor: float) -> str:
    """Divide two numbers.
    
    Args:
        dividend: The number to be divided
        divisor: The number to divide by
    """
    result = dividend / divisor  # This will raise ZeroDivisionError if divisor is 0
    return f"Result: {dividend} ÷ {divisor} = {result}"

# Create error handling middleware
@wrap_tool_call
def handle_tool_errors(request, handler):
    """Handle tool execution errors with custom messages."""
    try:
        return handler(request)
    except ZeroDivisionError:
        return ToolMessage(
            content="Error: Cannot divide by zero. Please provide a non-zero divisor.",
            tool_call_id=request.tool_call["id"]
        )
    except Exception as e:
        return ToolMessage(
            content=f"Tool error: An unexpected error occurred. Please check your input and try again. ({str(e)})",
            tool_call_id=request.tool_call["id"]
        )

print("Error handling middleware created!")</code></pre>

  <div class="exercise">
    <div class="exercise-title">Your Task</div>
    <p>
      Create an agent that uses the error-handling middleware and deliberately trigger an error (division by zero) to
      see how the agent responds.
    </p>
  </div>

  <pre><code># Create agent with error handling
error_handling_agent = create_agent(
    model=model,
    tools=[divide_numbers, calculator],
    middleware=[handle_tool_errors],
    system_prompt="You are a mathematical assistant. If you encounter errors, explain them clearly and suggest alternatives."
)

# Test error handling - this should trigger the error handler
print("Testing division by zero:")
result = error_handling_agent.invoke({
    "messages": [{"role": "user", "content": "Please divide 10 by 0"}]
})

print(result["messages"][-1].content)
print("\n" + "="*50 + "\n")</code></pre>

  <div class="exercise">
    <div class="exercise-title">Your Task</div>
    <p>Test a normal division to confirm that valid operations still work as expected.</p>
  </div>

  <pre><code># Test normal operation
print("Testing normal division:")
result = error_handling_agent.invoke({
    "messages": [{"role": "user", "content": "Please divide 10 by 2"}]
})
print(result["messages"][-1].content)</code></pre>

  <h2>9. System Prompts (Static and Dynamic)</h2>

  <h3>9.1 Static System Prompts</h3>
  <p>
    A <strong>system prompt</strong> defines the personality and behavior of your agent. A static system prompt is fixed when
    you create the agent.
  </p>

  <div class="exercise">
    <div class="exercise-title">Your Task</div>
    <p>
      Create an agent with a static system prompt that enforces a professional, polite style and clear calculations.
    </p>
  </div>

  <pre><code># Static system prompt example
static_prompt_agent = create_agent(
    model=model,
    tools=[calculator, get_weather],
    system_prompt="You are a professional assistant. Always be polite, concise, and accurate. When performing calculations, show your work clearly."
)

# Test static prompt
result = static_prompt_agent.invoke({
    "messages": [{"role": "user", "content": "Calculate 15 * 8 and tell me the weather in Paris"}]
})

print("Static Prompt Agent Response:")
print(result["messages"][-1].content)
print("\n" + "="*50 + "\n")</code></pre>

  <h3>9.2 Dynamic System Prompts</h3>
  <p>
    Dynamic prompts allow you to <strong>change the system prompt at runtime</strong> depending on a context object
    (for example, whether the user is a student, teacher, or expert).
  </p>

  <div class="exercise">
    <div class="exercise-title">Your Task</div>
    <p>
      Implement a dynamic system prompt using <code>@dynamic_prompt</code> and a simple context schema with
      <code>user_role</code> and <code>expertise_level</code>.
    </p>
  </div>

  <pre><code># Dynamic system prompt example
from langchain.agents.middleware import dynamic_prompt, ModelRequest

class Context(TypedDict):
    user_role: str
    expertise_level: str

@dynamic_prompt
def adaptive_system_prompt(request: ModelRequest) -> str:
    """Generate system prompt based on user context."""
    context = request.runtime.context if hasattr(request.runtime, 'context') else {}
    user_role = context.get("user_role", "general")
    expertise_level = context.get("expertise_level", "beginner")
    
    base_prompt = "You are a helpful assistant."
    
    if user_role == "student":
        if expertise_level == "beginner":
            return f"{base_prompt} Explain concepts simply, avoid jargon, and provide step-by-step explanations."
        else:
            return f"{base_prompt} Provide detailed explanations with examples and encourage critical thinking."
    elif user_role == "teacher":
        return f"{base_prompt} Provide comprehensive information that can be used for teaching, including examples and different perspectives."
    elif user_role == "expert":
        return f"{base_prompt} Provide detailed technical responses with advanced concepts and assume deep knowledge."
    
    return base_prompt

# Create dynamic prompt agent
dynamic_prompt_agent = create_agent(
    model=model,
    tools=[calculator, get_weather],
    middleware=[adaptive_system_prompt],
    context_schema=Context
)

print("Dynamic prompt agent created!")</code></pre>

  <div class="exercise">
    <div class="exercise-title">Your Task</div>
    <p>
      Invoke the dynamic prompt agent with different contexts (e.g., beginner student vs. expert) and compare how the
      explanations change.
    </p>
  </div>

  <pre><code># Test dynamic prompt with different contexts
print("Testing with beginner student context:")
result = dynamic_prompt_agent.invoke(
    {"messages": [{"role": "user", "content": "How do I calculate the area of a circle?"}]},
    context={"user_role": "student", "expertise_level": "beginner"}
)
print(result["messages"][-1].content)
print("\n" + "="*30 + "\n")

print("Testing with expert context:")
result = dynamic_prompt_agent.invoke(
    {"messages": [{"role": "user", "content": "How do I calculate the area of a circle?"}]},
    context={"user_role": "expert", "expertise_level": "advanced"}
)
print(result["messages"][-1].content)</code></pre>

  <h2>10. Guardrails for Agents</h2>
  <p>
    Now that you understand how to use <strong>middleware</strong>, let's apply it to a critical real-world problem:
    <strong>guardrails</strong> for safety, compliance, and control. Guardrails help ensure your agents do not leak PII,
    perform unsafe actions, or execute sensitive operations without human approval.
  </p>

  <div class="exercise">
    <div class="exercise-title">Your Task</div>
    <p>
      Import the guardrail-related middleware and helpers that we'll use in this section.
    </p>
  </div>

  <pre><code>from langchain.agents.middleware import PIIMiddleware, HumanInTheLoopMiddleware
from langgraph.checkpoint.memory import InMemorySaver
from langgraph.types import Command
from langchain.chat_models import init_chat_model</code></pre>

  <h3>10.1 Example Tools for Our Agent</h3>

  <p>
    Let's create some example tools that our agent will use. These tools simulate real-world scenarios where guardrails are essential.
  </p>

  <div class="exercise">
    <div class="exercise-title">Your Task</div>
    <p>
      Copy or type the following code to create example tools for testing guardrails:
    </p>
  </div>

  <pre><code>@tool
def send_email(recipient: str, subject: str, body: str) -> str:
    """Send an email to a recipient. This is a sensitive operation that requires approval."""
    return f"Email sent to {recipient} with subject '{subject}' and body: {body[:50]}..."

@tool
def search_database(query: str) -> str:
    """Search the company database for information."""
    return f"Database search results for '{query}': Found 5 matching records"

@tool
def delete_record(record_id: str) -> str:
    """Delete a record from the database. This is a sensitive operation."""
    return f"Record {record_id} has been deleted from the database"

@tool
def calculate(expression: str) -> str:
    """Calculate a mathematical expression."""
    try:
        # Simple calculator for safe expressions
        result = eval(expression.replace('^', '**'))
        return f"Result: {result}"
    except Exception as e:
        return f"Error in calculation: {str(e)}"

print("Guardrail tools created successfully!")</code></pre>

  <h3>10.2 Built-in Guardrail: PII Detection</h3>

  <p>
    LangChain provides built-in middleware for detecting and handling Personally Identifiable Information (PII). This is crucial for compliance with regulations like GDPR and HIPAA.
  </p>

  <h4>PII Detection Strategies:</h4>
  <ul>
    <li><strong>redact</strong>: Replace with [REDACTED_TYPE]</li>
    <li><strong>mask</strong>: Partially obscure (e.g., ****-****-****-1234)</li>
    <li><strong>hash</strong>: Replace with deterministic hash</li>
    <li><strong>block</strong>: Raise exception when detected</li>
  </ul>

  <div class="exercise">
    <div class="exercise-title">Your Task</div>
    <p>
      Create an agent with PII detection guardrails. Copy or type the following code:
    </p>
  </div>

  <pre><code># Create an agent with PII detection guardrails
pii_agent = create_agent(
    model=init_chat_model("gpt-4.1-mini"),
    tools=[send_email, search_database, calculate],
    middleware=[
        # Redact emails in user input before sending to model
        PIIMiddleware(
            "email",
            strategy="redact",
            apply_to_input=True,
        ),
        # Mask credit cards in user input (example, commented out)
        # PIIMiddleware(
        #     "credit_card",
        #     strategy="hash",
        #     apply_to_input=True,
        # ),
        # Mask API keys in user input
        PIIMiddleware(
            "api_key",
            detector=r"sk-[a-zA-Z0-9]{32}",  # OpenAI API key pattern
            strategy="mask",
            apply_to_input=True,
        ),
    ],
)

print("PII-protected agent created!")</code></pre>

  <div class="exercise">
    <div class="exercise-title">Your Task</div>
    <p>
      Test PII detection with email and API key. Copy or type the following code:
    </p>
  </div>

  <pre><code># Test PII detection with email and API key
print("=== Testing PII Detection ===")
print("Input: 'My email is john.doe@example.com and my API key is sk-abcdefghijklmnopqrstuvwxyz123456'")
print()

try:
    result = pii_agent.invoke({
        "messages": [{
            "role": "user", 
            "content": "My email is john.doe@example.com and My API key is sk-abcdefghijklmnopqrstuvwxyz123456. Can you help me with customer service?"
        }]
    })
    
    print("Agent Response:")
    print(result['messages'])
    
except Exception as e:
    print(f"Error: {e}")</code></pre>

  <h3>10.3 Built-in Guardrail: Human-in-the-Loop</h3>

  <p>
    Human-in-the-loop middleware requires human approval before executing sensitive operations. This is perfect for high-stakes decisions like financial transactions or data deletion.
  </p>

  <div class="exercise">
    <div class="exercise-title">Your Task</div>
    <p>
      Create an agent with human-in-the-loop for sensitive operations. Copy or type the following code:
    </p>
  </div>

  <pre><code># Create an agent with human-in-the-loop for sensitive operations
hitl_agent = create_agent(
    model=init_chat_model("gpt-4o-mini"),
    tools=[send_email, search_database, delete_record, calculate],
    middleware=[
        HumanInTheLoopMiddleware(
            interrupt_on={
                # Require approval for sensitive operations
                "send_email": True,
                "delete_record": True,
                # Auto-approve safe operations
                "search_database": False,
                "calculate": False,
            }
        ),
    ],
    # Persist the state across interrupts
    checkpointer=InMemorySaver(),
)

print("Human-in-the-loop agent created!")</code></pre>

  <div class="exercise">
    <div class="exercise-title">Your Task</div>
    <p>
      Test human-in-the-loop with a safe operation (should execute immediately). Copy or type the following code:
    </p>
  </div>

  <pre><code># Test human-in-the-loop with a safe operation (should execute immediately)
print("=== Testing Safe Operation (No Approval Needed) ===")
print("Request: Calculate 25 * 4")
print()

config = {"configurable": {"thread_id": "safe_thread"}}

result = hitl_agent.invoke(
    {"messages": [{"role": "user", "content": "Calculate 25 * 4"}]},
    config=config
)

print("Agent Response:")
result['messages']</code></pre>

  <div class="exercise">
    <div class="exercise-title">Your Task</div>
    <p>
      Test human-in-the-loop with a sensitive operation (requires approval). Copy or type the following code:
    </p>
  </div>

  <pre><code># Test human-in-the-loop with a sensitive operation (requires approval)
print("=== Testing Sensitive Operation (Requires Approval) ===")
print("Request: Send an email to the team")
print()

config = {"configurable": {"thread_id": "sensitive_thread"}}

# This will pause and wait for approval
result = hitl_agent.invoke(
    {"messages": [{"role": "user", "content": "Send an email to team@company.com about the quarterly meeting"}]},
    config=config
)

print("Initial Response (Waiting for Approval):")
print(f"Messages: {len(result.get('messages', []))}")
print(f"Next step: {result.get('next', 'Unknown')}")
print("\n⏸️ Agent paused, waiting for human approval...")</code></pre>

  <div class="exercise">
    <div class="exercise-title">Your Task</div>
    <p>
      Approve the sensitive operation. Copy or type the following code:
    </p>
  </div>

  <pre><code># Approve the sensitive operation
print("=== Human Approval: APPROVE ===")
print()

# Resume with approval
approved_result = hitl_agent.invoke(
    Command(resume={"decisions": [{"type": "approve"}]}),
    config=config  # Same thread ID to resume
)

print("Final Response After Approval:")
approved_result['messages']</code></pre>

  <div class="exercise">
    <div class="exercise-title">Your Task</div>
    <p>
      Demonstrate rejection. Copy or type the following code:
    </p>
  </div>

  <pre><code># Demonstrate rejection
print("=== Testing Rejection ===")
print("Request: Delete a record")
print()

config_reject = {"configurable": {"thread_id": "reject_thread1"}}

# Start a sensitive operation
result = hitl_agent.invoke(
    {"messages": [{"role": "user", "content": "Delete record ID-12345 from the database"}]},
    config=config_reject
)

print("⏸️ Agent paused for approval...")
print("Human Decision: REJECT")
print()

# Reject the operation
rejected_result = hitl_agent.invoke(
    Command(resume={"decisions": [{"type": "reject"}]}),
    config=config_reject
)

print("Final Response After Rejection:")
rejected_result['messages']</code></pre>

</main>
</body>
</html>


